{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f995a9",
   "metadata": {},
   "source": [
    "# PVAnalytics QA Process: Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e9027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvanalytics\n",
    "import numpy as np\n",
    "import rdtools\n",
    "from statistics import mode\n",
    "import json\n",
    "# pvanalytics.__version__\n",
    "from pvanalytics.features.clearsky import reno       #update to just do a pvanalytics import?\n",
    "import pvlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pvanalytics.quality import data_shifts as ds\n",
    "from pvanalytics.quality import gaps\n",
    "from pvanalytics.quality.outliers import zscore\n",
    "from pvanalytics.features.daytime import power_or_irradiance\n",
    "from pvanalytics.quality.time import shifts_ruptures\n",
    "from pvanalytics.features import daytime\n",
    "from pvanalytics.system import (is_tracking_envelope,\n",
    "                                infer_orientation_fit_pvwatts)\n",
    "from pvanalytics.features.clipping import geometric\n",
    "import ruptures as rpt\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12,\n",
    "                           'figure.figsize': [4.5, 3],\n",
    "                           'lines.markeredgewidth': 0,\n",
    "                           'lines.markersize': 2\n",
    "                           })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8eec15",
   "metadata": {},
   "source": [
    "In the following example, a process for assessing the data quality of the AC power data streams for system 2107 is shown, using PVAnalytics functions. This example pipeline illustrates how several PVAnalytics functions can be used in sequence to assess the quality of a power data stream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666aaf80",
   "metadata": {},
   "source": [
    "First, we download and import the power data from a PV installation under the [2023 solar data prize data set](https://data.openei.org/s3_viewer?bucket=oedi-data-lake&limit=100&prefix=pvdaq%2F2023-solar-data-prize%2F). This data set is publicly available via the PVDAQ database in the DOE Open Energy Data Initiative (OEDI) (https://data.openei.org/submissions/4568), under system ID 2107. This data is timezone-localized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ace5281",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/2107_system_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "tz = metadata['System']['timezone_code']\n",
    "\n",
    "def load_csv(file_path):\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        index_col=0,\n",
    "        parse_dates=True,\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df_elect = load_csv(\"./data/2107_electrical_data.csv\")\n",
    "\n",
    "df_elect = df_elect.tz_localize(tz, ambiguous=True)\n",
    "\n",
    "power_columns = [x for x in df_elect.columns if 'power' in x]\n",
    "\n",
    "latitude = metadata['Site']['latitude']\n",
    "longitude = metadata['Site']['longitude']\n",
    "\n",
    "# Get irradiance column and turn it into a series\n",
    "# irradiance is sampled every 5 minutes \n",
    "irradiance_time_series = df_irrad['poa_irradiance_o_149574'].copy()\n",
    "\n",
    "# Get the time frequency of the time series\n",
    "freq_minutes = mode(irradiance_time_series.index.to_series().diff().dt.seconds / 60)\n",
    "data_freq = str(freq_minutes) + \"min\"\n",
    "irradiance_time_series = irradiance_time_series.asfreq(data_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce894c",
   "metadata": {},
   "source": [
    "First let's visualize the data pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_time_series.plot(title=\"Original Time Series\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Power (kW)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9144de8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 116\u001b[0m\n\u001b[0;32m    109\u001b[0m modeled_midday_series_daily \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    110\u001b[0m     (modeled_midday_series_daily\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    111\u001b[0m      modeled_midday_series_daily\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mminute \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    112\u001b[0m      modeled_midday_series_daily\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39msecond \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Estimate the time shifts by comparing the modelled midday point to the\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# measured midday point.\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m is_shifted, time_shift_series \u001b[38;5;241m=\u001b[39m \u001b[43mshifts_ruptures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmidday_series_daily\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mmodeled_midday_series_daily\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mperiod_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mshift_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mzscore_cutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Create a midday difference series between modeled and measured midday, to\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# visualize time shifts. First, resample each time series to daily frequency,\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# and compare the data stream's daily halfway point to the modeled halfway\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# point\u001b[39;00m\n\u001b[0;32m    126\u001b[0m midday_diff_series \u001b[38;5;241m=\u001b[39m (midday_series\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m-\u001b[39m\n\u001b[0;32m    127\u001b[0m                       modeled_midday_series\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m    128\u001b[0m                       )\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtotal_seconds() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pvfleets_qa_analysis\\lib\\site-packages\\pvanalytics\\quality\\time.py:158\u001b[0m, in \u001b[0;36mshifts_ruptures\u001b[1;34m(event_times, reference_times, period_min, shift_min, prediction_penalty, zscore_cutoff, bottom_quantile_threshold, top_quantile_threshold)\u001b[0m\n\u001b[0;32m    156\u001b[0m time_diff \u001b[38;5;241m=\u001b[39m time_diff\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Run changepoint detection to find breaks\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m break_points \u001b[38;5;241m=\u001b[39m \u001b[43mruptures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBinseg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrbf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mjump\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperiod_min\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43msignal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_diff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mpen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_penalty\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# Make sure the entire series is covered by the intervals between\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# the breakpoints that were identified above. This means adding a\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# breakpoint at the beginning of the series (0) and at the end if\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# one does not already exist.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m break_points\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pvfleets_qa_analysis\\lib\\site-packages\\ruptures\\detection\\binseg.py:174\u001b[0m, in \u001b[0;36mBinseg.fit_predict\u001b[1;34m(self, signal, n_bkps, pen, epsilon)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit to the signal and return the optimal breakpoints.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03mHelper method to call fit and predict once\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03m    list: sorted list of breakpoints\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(signal)\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_bkps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_bkps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pvfleets_qa_analysis\\lib\\site-packages\\ruptures\\detection\\binseg.py:155\u001b[0m, in \u001b[0;36mBinseg.predict\u001b[1;34m(self, n_bkps, pen, epsilon)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sanity_check(\n\u001b[0;32m    148\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    149\u001b[0m     n_bkps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_bkps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m n_bkps,\n\u001b[0;32m    150\u001b[0m     jump\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjump,\n\u001b[0;32m    151\u001b[0m     min_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_size,\n\u001b[0;32m    152\u001b[0m ):\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadSegmentationParameters\n\u001b[1;32m--> 155\u001b[0m partition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_seg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_bkps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_bkps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m bkps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(e \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m partition\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bkps\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pvfleets_qa_analysis\\lib\\site-packages\\ruptures\\detection\\binseg.py:54\u001b[0m, in \u001b[0;36mBinseg._seg\u001b[1;34m(self, n_bkps, pen, epsilon)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop:\n\u001b[0;32m     53\u001b[0m     stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     new_bkps \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_bkp(start, end) \u001b[38;5;28;01mfor\u001b[39;00m start, end \u001b[38;5;129;01min\u001b[39;00m pairwise([\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m bkps)\n\u001b[0;32m     56\u001b[0m     ]\n\u001b[0;32m     57\u001b[0m     bkp, gain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(new_bkps, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bkp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# all possible configuration have been explored.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pvfleets_qa_analysis\\lib\\site-packages\\ruptures\\detection\\binseg.py:55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop:\n\u001b[0;32m     53\u001b[0m     stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     new_bkps \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 55\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_bkp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m start, end \u001b[38;5;129;01min\u001b[39;00m pairwise([\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m bkps)\n\u001b[0;32m     56\u001b[0m     ]\n\u001b[0;32m     57\u001b[0m     bkp, gain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(new_bkps, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bkp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# all possible configuration have been explored.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pvfleets_qa_analysis\\lib\\site-packages\\ruptures\\detection\\binseg.py:94\u001b[0m, in \u001b[0;36mBinseg.single_bkp\u001b[1;34m(self, start, end)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bkp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start, end, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjump):\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bkp \u001b[38;5;241m-\u001b[39m start \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_size \u001b[38;5;129;01mand\u001b[39;00m end \u001b[38;5;241m-\u001b[39m bkp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_size:\n\u001b[0;32m     91\u001b[0m         gain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     92\u001b[0m             segment_cost\n\u001b[0;32m     93\u001b[0m             \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost\u001b[38;5;241m.\u001b[39merror(start, bkp)\n\u001b[1;32m---> 94\u001b[0m             \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbkp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m         )\n\u001b[0;32m     96\u001b[0m         gain_list\u001b[38;5;241m.\u001b[39mappend((gain, bkp))\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pvfleets_qa_analysis\\lib\\site-packages\\ruptures\\costs\\costrbf.py:79\u001b[0m, in \u001b[0;36mCostRbf.error\u001b[1;34m(self, start, end)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotEnoughPoints\n\u001b[0;32m     78\u001b[0m sub_gram \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgram[start:end, start:end]\n\u001b[1;32m---> 79\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiagonal\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_gram\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m val \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m sub_gram\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m (end \u001b[38;5;241m-\u001b[39m start)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for col in power_columns:\n",
    "    power_time_series = df_elect[col].copy()\n",
    "\n",
    "    # Get the time frequency of the time series\n",
    "    freq_minutes = mode(power_time_series.index.to_series().diff().dt.seconds / 60)\n",
    "    data_freq = str(freq_minutes) + \"min\"\n",
    "    power_time_series = power_time_series.asfreq(data_freq)    \n",
    "\n",
    "    # REMOVE STALE DATA (that isn't during nighttime periods)\n",
    "    # Day/night mask\n",
    "    daytime_mask = power_or_irradiance(power_time_series)\n",
    "    # Stale data mask\n",
    "    stale_data_mask = gaps.stale_values_round(power_time_series,\n",
    "                                              window=3,\n",
    "                                              decimals=2)\n",
    "    stale_data_mask = stale_data_mask & daytime_mask\n",
    "\n",
    "    # REMOVE NEGATIVE DATA\n",
    "    negative_mask = (power_time_series < 0)\n",
    "\n",
    "    # FIND ABNORMAL PERIODS\n",
    "    daily_min = power_time_series.resample('D').min()\n",
    "    series_min = 0.1 * power_time_series.mean()\n",
    "    erroneous_mask = (daily_min >= series_min)\n",
    "    erroneous_mask = erroneous_mask.reindex(index=power_time_series.index,\n",
    "                                            method='ffill',\n",
    "                                            fill_value=False)\n",
    "\n",
    "    # FIND OUTLIERS (Z-SCORE FILTER)\n",
    "    zscore_outlier_mask = zscore(power_time_series, zmax=4,\n",
    "                                 nan_policy='omit')\n",
    "\n",
    "    # Get the percentage of data flagged for each issue, so it can later be logged\n",
    "    pct_stale = round((len(power_time_series[\n",
    "        stale_data_mask].dropna())/len(power_time_series.dropna())*100), 1)\n",
    "    pct_negative = round((len(power_time_series[\n",
    "        negative_mask].dropna())/len(power_time_series.dropna())*100), 1)\n",
    "    pct_erroneous = round((len(power_time_series[\n",
    "        erroneous_mask].dropna())/len(power_time_series.dropna())*100), 1)\n",
    "    pct_outlier = round((len(power_time_series[\n",
    "        zscore_outlier_mask].dropna())/len(power_time_series.dropna())*100), 1)\n",
    "\n",
    "\n",
    "\n",
    "    # Filter the time series, taking out all of the issues\n",
    "    issue_mask = ((~stale_data_mask) & (~negative_mask) &\n",
    "              (~erroneous_mask) & (~zscore_outlier_mask))\n",
    "\n",
    "    power_time_series = power_time_series[issue_mask].copy()\n",
    "    power_time_series = power_time_series.asfreq(data_freq)\n",
    "\n",
    "\n",
    "    # daily data completeness\n",
    "    x = power_time_series.copy()\n",
    "    x.loc[~daytime_mask] = 0\n",
    "    data_completeness_score = gaps.completeness_score(x)\n",
    "\n",
    "\n",
    "    # Trim the series based on daily completeness score\n",
    "    trim_series = pvanalytics.quality.gaps.trim_incomplete(\n",
    "        x, minimum_completeness=.25, freq=data_freq)\n",
    "\n",
    "    power_time_series = power_time_series[trim_series].copy()\n",
    "    power_time_series = power_time_series.asfreq(data_freq)\n",
    "\n",
    "    # Get time of day from the associated datetime column\n",
    "    time_of_day = pd.Series(power_time_series.index.hour +\n",
    "                            power_time_series.index.minute/60,\n",
    "                            index=power_time_series.index)\n",
    "    # Pivot the dataframe\n",
    "    dataframe = pd.DataFrame(pd.concat([power_time_series, time_of_day], axis=1))\n",
    "    dataframe.columns = [\"values\", 'time_of_day']\n",
    "    dataframe = dataframe.dropna()\n",
    "    dataframe_pivoted = dataframe.pivot_table(index='time_of_day',\n",
    "                                              columns=dataframe.index.date,\n",
    "                                              values=\"values\")\n",
    "\n",
    "    # Get the modeled sunrise and sunset time series based on the system's\n",
    "    # latitude-longitude coordinates\n",
    "    modeled_sunrise_sunset_df = pvlib.solarposition.sun_rise_set_transit_spa(\n",
    "         power_time_series.index, latitude, longitude)\n",
    "\n",
    "    # Calculate the midday point between sunrise and sunset for each day\n",
    "    # in the modeled irradiance series\n",
    "    modeled_midday_series = modeled_sunrise_sunset_df['sunrise'] + \\\n",
    "        (modeled_sunrise_sunset_df['sunset'] -\n",
    "         modeled_sunrise_sunset_df['sunrise']) / 2\n",
    "\n",
    "    # Run day-night mask on the power time series\n",
    "    daytime_mask = power_or_irradiance(power_time_series,\n",
    "                                       freq=data_freq,\n",
    "                                       low_value_threshold=.005)\n",
    "\n",
    "    # Generate the sunrise, sunset, and halfway points for the data stream\n",
    "    sunrise_series = daytime.get_sunrise(daytime_mask)\n",
    "    sunset_series = daytime.get_sunset(daytime_mask)\n",
    "    midday_series = sunrise_series + ((sunset_series - sunrise_series)/2)\n",
    "\n",
    "    # Convert the midday and modeled midday series to daily values\n",
    "    midday_series_daily, modeled_midday_series_daily = (\n",
    "        midday_series.resample('D').mean(),\n",
    "        modeled_midday_series.resample('D').mean())\n",
    "\n",
    "    # Set midday value series as minutes since midnight, from midday datetime\n",
    "    # values\n",
    "    midday_series_daily = (midday_series_daily.dt.hour * 60 +\n",
    "                           midday_series_daily.dt.minute +\n",
    "                           midday_series_daily.dt.second / 60)\n",
    "    modeled_midday_series_daily = \\\n",
    "        (modeled_midday_series_daily.dt.hour * 60 +\n",
    "         modeled_midday_series_daily.dt.minute +\n",
    "         modeled_midday_series_daily.dt.second / 60)\n",
    "\n",
    "    # Estimate the time shifts by comparing the modelled midday point to the\n",
    "    # measured midday point.\n",
    "    is_shifted, time_shift_series = shifts_ruptures(midday_series_daily,\n",
    "                                                    modeled_midday_series_daily,\n",
    "                                                    period_min=15,\n",
    "                                                    shift_min=15,\n",
    "                                                    zscore_cutoff=1.5)\n",
    "\n",
    "    # Create a midday difference series between modeled and measured midday, to\n",
    "    # visualize time shifts. First, resample each time series to daily frequency,\n",
    "    # and compare the data stream's daily halfway point to the modeled halfway\n",
    "    # point\n",
    "    midday_diff_series = (midday_series.resample('D').mean() -\n",
    "                          modeled_midday_series.resample('D').mean()\n",
    "                          ).dt.total_seconds() / 60\n",
    "\n",
    "    # Generate boolean for detected time shifts\n",
    "    if any(time_shift_series != 0):\n",
    "        time_shifts_detected = True\n",
    "    else:\n",
    "        time_shifts_detected = False\n",
    "\n",
    "    # Build a list of time shifts for re-indexing. We choose to use dicts.\n",
    "    time_shift_series.index = pd.to_datetime(\n",
    "        time_shift_series.index)\n",
    "    changepoints = (time_shift_series != time_shift_series.shift(1))\n",
    "    changepoints = changepoints[changepoints].index\n",
    "    changepoint_amts = pd.Series(time_shift_series.loc[changepoints])\n",
    "    time_shift_list = list()\n",
    "    for idx in range(len(changepoint_amts)):\n",
    "        if changepoint_amts[idx] == 0:\n",
    "            change_amt = 0\n",
    "        else:\n",
    "            change_amt = -1 * changepoint_amts[idx]\n",
    "        if idx < (len(changepoint_amts) - 1):\n",
    "            time_shift_list.append({\"datetime_start\":\n",
    "                                    str(changepoint_amts.index[idx]),\n",
    "                                    \"datetime_end\":\n",
    "                                        str(changepoint_amts.index[idx + 1]),\n",
    "                                    \"time_shift\": change_amt})\n",
    "        else:\n",
    "            time_shift_list.append({\"datetime_start\":\n",
    "                                    str(changepoint_amts.index[idx]),\n",
    "                                    \"datetime_end\":\n",
    "                                        str(time_shift_series.index.max()),\n",
    "                                    \"time_shift\": change_amt})\n",
    "\n",
    "    # Correct any time shifts in the time series\n",
    "    new_index = pd.Series(power_time_series.index, index=power_time_series.index).dropna()\n",
    "    for i in time_shift_list:\n",
    "        if pd.notna(i['time_shift']):\n",
    "            new_index[(power_time_series.index >= pd.to_datetime(i['datetime_start'])) &\n",
    "                  (power_time_series.index < pd.to_datetime(i['datetime_end']))] = \\\n",
    "            power_time_series.index + pd.Timedelta(minutes=i['time_shift'])\n",
    "    power_time_series.index = new_index\n",
    "\n",
    "    # Remove duplicated indices and sort the time series (just in case)\n",
    "    power_time_series = power_time_series[~power_time_series.index.duplicated(\n",
    "        keep='first')].sort_index()\n",
    "\n",
    "    # Set all values in the nighttime mask to 0\n",
    "    power_time_series.loc[~daytime_mask] = 0\n",
    "    # Resample the time series to daily mean\n",
    "    power_time_series_daily = power_time_series.resample('D').mean()\n",
    "    data_shift_start_date, data_shift_end_date = \\\n",
    "        ds.get_longest_shift_segment_dates(power_time_series_daily,\n",
    "                                           use_default_models=False,\n",
    "                                           method=rpt.Binseg, cost='rbf',\n",
    "                                           penalty=15)\n",
    "    data_shift_period_length = (data_shift_end_date -\n",
    "                                data_shift_start_date).days\n",
    "\n",
    "    # Get the number of shift dates\n",
    "    data_shift_mask = ds.detect_data_shifts(power_time_series_daily,\n",
    "                                            use_default_models=False,\n",
    "                                            method=rpt.Binseg, cost='rbf',\n",
    "                                            penalty=15)\n",
    "    # Get the shift dates\n",
    "    shift_dates = list(power_time_series_daily[data_shift_mask].index)\n",
    "    if len(shift_dates) > 0:\n",
    "        shift_found = True\n",
    "    else:\n",
    "        shift_found = False\n",
    "    \n",
    "    power_time_series = power_time_series[\n",
    "        (power_time_series.index >=\n",
    "         data_shift_start_date.tz_convert(power_time_series.index.tz)) &\n",
    "        (power_time_series.index <=\n",
    "         data_shift_end_date.tz_convert(power_time_series.index.tz))]\n",
    "\n",
    "    power_time_series = power_time_series.asfreq(data_freq)\n",
    "    power_time_series.to_csv(os.path.join(\"./data\",  col + \".pkl\"))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
